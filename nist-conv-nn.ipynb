{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":10705,"sourceType":"datasetVersion","datasetId":7160},{"sourceId":2205796,"sourceType":"datasetVersion","datasetId":1093},{"sourceId":11506,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":9280},{"sourceId":13346,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":11048}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mihaail/nist-conv-nn?scriptVersionId=168072114\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nfrom torch import optim\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader \nfrom torchmetrics import Accuracy, MeanAbsoluteError, Precision\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom tqdm import tqdm\nfrom torchvision.datasets import MNIST\nimport torchvision\nimport torchvision.transforms.v2 as T\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\n\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T16:57:03.849743Z","iopub.execute_input":"2024-03-17T16:57:03.850362Z","iopub.status.idle":"2024-03-17T16:57:12.210254Z","shell.execute_reply.started":"2024-03-17T16:57:03.850326Z","shell.execute_reply":"2024-03-17T16:57:12.209414Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"First model:\n  accuracy = 0.992\n  loss = \n\nSecond model: accuracy = 0.993\nloss = \n\nОбучение на датасете Emnist\nthird model: precision = 0.87\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Первая и вторая модель для обучения на датасете MNIST\nу этих моделей есть ошибка в том, что перед последним слоем стоит не softmax а ReLU\n","metadata":{}},{"cell_type":"markdown","source":"\n## 2. Третья модель \n1. Зафайнтюнить вторую модель для обучения на emnist не получилось. слишко плохое качество. precision=0.5. \n\n2. заменим метрику с accuracy на precision\n\n","metadata":{}},{"cell_type":"markdown","source":"\n## 3. Четвёртая модель\n2. заменяется ReLU перед последним слоем на softmax\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Оценим датасет EMNIST","metadata":{}},{"cell_type":"markdown","source":"### Создаем датасет и даталоадер. ","metadata":{}},{"cell_type":"markdown","source":"## Загружется и обрабатывается датасет EMNIST","metadata":{}},{"cell_type":"code","source":"# Создается класс для чтения dataset из csv файла \nclass CustomDatasetEMNIST():\n    def __init__(self, csv_file_path, \n                 transform=None,\n                 nrows=None,\n                 skiprows=None) :\n        '''nrows - кол-во строк которое необходимо подгрузить,\n        '''\n        super().__init__()\n        self.data, self.targets, self.dataframe = self._load_data(csv_file_path=csv_file_path, nrows=nrows, skiprows=skiprows)\n        \n        self.transform = transform\n        \n    def __len__(self) :\n        return len(self.data) \n    \n    def __getitem__(self, index) :\n       \n        img = self.data[index]\n        #print(f'1. {img.shape=} {img}/n') \n        img = img.unsqueeze(0)\n        #print(f'2.{img.shape=} {img}/n') \n        targets = int(self.targets[index])\n        # Повернем и отразим изображение для лучшего восприятия\n        img = torchvision.transforms.functional.rotate(img=img, angle=-90)\n        img = torch.flip(img, dims=(2,))\n        \n        #print(f'3 {img.shape} {img} /n') \n        \n        if self.transform is not None:\n            #print(f'3. {img.shape} {img}') \n\n            img = self.transform(img)\n            #print(f'4.{img.shape} {img}') \n\n            \n        return img, targets\n    \n    \n    def _load_data(self,\n                  csv_file_path,\n                  nrows,\n                  skiprows=None):\n        \n        df = pd.read_csv(csv_file_path, nrows=nrows, skiprows=skiprows) \n        \n        targets = torch.tensor(df.iloc[:,0].values)\n        \n        data = df.iloc[:,1:].values.reshape((len(df), 28, 28))\n        \n        return torch.tensor(data).float(), targets, df","metadata":{"execution":{"iopub.status.busy":"2024-03-17T16:57:12.211778Z","iopub.execute_input":"2024-03-17T16:57:12.212219Z","iopub.status.idle":"2024-03-17T16:57:12.223096Z","shell.execute_reply.started":"2024-03-17T16:57:12.212194Z","shell.execute_reply":"2024-03-17T16:57:12.222011Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Зададим функции обучения валидации и отрисовки графиков","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:20:04.69551Z","iopub.execute_input":"2024-03-02T06:20:04.695755Z","iopub.status.idle":"2024-03-02T06:20:04.70631Z","shell.execute_reply.started":"2024-03-02T06:20:04.695734Z","shell.execute_reply":"2024-03-02T06:20:04.705565Z"}}},{"cell_type":"code","source":"#Зададим девайс для обучения        \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\nprint(device)\ntry:\n    print(torch.cuda.get_device_name())\nexcept:\n    print('GPU нету!')\n        \n\n    \ndef train(model: nn.Module,\n         loader: DataLoader,\n         loss_fn,\n         metric) -> tuple[float, float]: \n    \n    '''ф-я проводит обучение модели. \n    возвращает ошибку на трейновом датасете'''\n    \n    model.train()\n    total_loss = 0\n    total_metric = 0\n\n    for x, y in tqdm(loader, desc=\"Train\"):\n        x, y = x.to(device), y.to(device)\n        \n        optimizer.zero_grad() \n    \n        output = model(x) \n    \n        loss = loss_fn(output, y) \n        total_loss += loss.item()\n        \n        loss.backward() \n    \n        optimizer.step()\n        \n        total_metric +=  metric(output.detach(), y).item()\n        \n    total_loss /= len(loader)\n    total_metric /= len(loader) \n    \n    return total_loss, total_metric \n\n\n@torch.inference_mode() \ndef valid(model: nn.Module,\n         loader: DataLoader,\n         loss_fn,\n         metric) -> tuple[float, float] :\n    \n    '''Ф-я расчитывает ф-ю ошибки и метрику на валидационной выборке'''\n    model.eval() \n    \n    total_loss = 0\n    total_metric = 0\n    \n    for x, y in tqdm(loader, desc=\"Evaluation\"):\n        x, y = x.to(device), y.to(device)\n        \n        output = model(x) \n        \n        loss = loss_fn(output, y) \n        \n        total_loss += loss.item()\n        \n        total_metric += metric(output, y).item() \n        \n        \n    total_loss /= len(loader)\n    total_metric /= len(loader) \n    return total_loss, total_metric\n          \n\ndef plot_stats(\n    train_loss: tuple,\n    valid_loss: tuple, \n    train_metric: tuple, \n    valid_metric: tuple, \n    title: str,\n    metric_name: str ) :\n    '''Ф-я отрисовывает ошибку и метрику на тестовой и трейновой датасетах.\n    '''\n    plt.figure(figsize=(8, 5))\n    plt.title(f'{title} loss') \n    plt.plot(train_loss, label='Train loss') \n    plt.plot(valid_loss, label='Valid loss') \n    \n    plt.legend() \n    plt.grid() \n    \n    plt.figure(figsize=(8, 5))\n    plt.title(f'{title} {metric_name}')\n    plt.plot(train_metric, label=f'Train {metric_name}') \n    plt.plot(valid_metric, label=f'Valid {metric_name}') \n    plt.legend() \n    \n    plt.grid() \n    \n    plt.show() \n\n\n    \n#Функция обучения и валидации на всех эпохах\n\ndef train_test_cycle(model: nn.Module,\n                    num_epochs: int, \n                    loss_fn, \n                    train_loader: DataLoader, \n                    valid_loader: DataLoader,\n                    metric,\n                    metric_name: str,\n                    title: str,\n                    scheduler):\n    '''Ф-я проводит для каждой эпох обучение на трейновой выборке, валидацию для валидной выборки\n    и отрисовку графиков. '''\n    \n    train_loss_history, train_metric_history = [], []\n    valid_loss_history, valid_metric_history = [], []\n    \n    \n    for epoch in range(num_epochs): \n        train_loss, train_metric = train(model,\n                          train_loader, \n                          loss_fn,\n                          metric)\n        \n        valid_loss, valid_metric = valid(model, \n                           valid_loader, \n                           loss_fn, \n                           metric) \n        \n        train_loss_history.append(train_loss) \n        valid_loss_history.append(valid_loss) \n        \n        train_metric_history.append(train_metric) \n        valid_metric_history.append(valid_metric)\n                \n        clear_output()\n        \n        plot_stats(train_loss_history, \n                  valid_loss_history, \n                  train_metric_history, \n                  valid_metric_history, \n                  title,\n                  metric_name) \n        \n        scheduler.step() \n        print(f'Valid Loss: {valid_loss}') \n        print(f'Valid {metric_name}: {valid_metric}') \n\n        \n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Создаем объект нс","metadata":{}},{"cell_type":"code","source":"emnist_data = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-train.csv', \ntransform=T.Compose([T.ToImage(),\nT.ToDtype(torch.float32, scale=True)]))\n\n\n# Зададим mean и std для нормализации входных данных\nmean = (emnist_data.data/255).mean().unsqueeze(0) \nstd = (emnist_data.data/255).std().unsqueeze(0) \nprint(f'{mean=}') \nprint(f'{std=}') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#чтобы не вычислять заново среднее и стандартное отклонение и не подгуржать датафрейм запишем эти данные как константы\n\n'''emnist_data = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-train.csv', \ntransform=T.Compose([T.ToImage(),\nT.ToDtype(torch.float32, scale=True)]))\n\n\n# Зададим mean и std для нормализации входных данных\nmean = (emnist_data.data/255).mean().unsqueeze(0) \nstd = (emnist_data.data/255).std().unsqueeze(0) \nprint(f'{mean=}') \nprint(f'{std=}') '''\n\nmean = torch.tensor([0.1736])\nstd = torch.tensor([0.3317])\n\n\n# Зададим трансформацию для трейн и тест датасетов\ntrain_transforms = T.Compose(\n    [\n        T.Resize([28, 28]),\n        T.ToTensor(),\n        T.Normalize(mean=mean, std=std), \n        T.RandomAdjustSharpness(sharpness_factor=2),\n        T.RandomRotation(degrees=20),\n#         T.RandomZoomOut(),\n       # T.RandomResizedCrop(size=(28, 28), scale=(0.5, 1.0)),\n        #T.RandomPerspective()\n    ]\n) \n\nvalid_transforms = T.Compose(\n    [\n        T.Resize([28, 28]),\n        T.ToTensor(),\n        T.Normalize(mean=mean, std=std)\n        \n        \n    ]\n) \n# plt.figure(figsize=(3, 3))\n# plt.title(f'Цифра {emnist_data[1][1]}')\n# plt.imshow(emnist_data[1][0][0])\n\n# plt.show()\n\n#Для обучения не будем подгружать датасет. чтобы не занимать оперативную память \n'''\ndf = pd.read_csv('/kaggle/input/emnist/emnist-byclass-train.csv')\n\ndf.head(2)\n\n#выведем классы изображений и запишем их кол-во\nclasses = df.iloc[:,0]\nprint(np.sort(classes.unique()))\nemnist_num_classes = classes.nunique()\nprint(emnist_num_classes)\n\n#Оценим распределение классов в датасете\nplt.figure(figsize=(5,5))\nplt.hist(classes,bins=emnist_num_classes, orientation='horizontal', alpha=0.5)\nplt.show()\n\nКак видно из графика присутствует сильный перекос в классах данных\n'''\nemnist_num_classes = 62\n\ntrain_dataset = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-train.csv', \n                                    \n#                                     skiprows=50000,\n                                    nrows=300000, \n                                    transform=train_transforms) \n\nvalid_dataset = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-test.csv',\n#                                    nrows=100000, \n                                    transform=valid_transforms) \n\ntrain_loader = DataLoader(train_dataset, batch_size=500, shuffle=True) \nvalid_loader = DataLoader(valid_dataset, batch_size=500, shuffle=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим класс (и архитектуру) третьей модели. Для обучения на датасете EMNIST\n\nclass ThirdModel(nn.Module) :\n    def __init__(self) :\n        super().__init__() \n        # Размерность входного тензора: 1х28х28\n       \n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels=1,\n                      out_channels=64,\n                      kernel_size=3,\n                      padding=1\n                     ), #64x26x26\n            nn.BatchNorm2d(64), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=64,\n                      out_channels=64,\n                      kernel_size=3, \n                      padding=1) , #64x28x28\n            nn.BatchNorm2d(64), \n            nn.ReLU(), \n     \n            \n            nn.MaxPool2d(kernel_size=2), #64x14x14\n            nn.Dropout2d(p=0.2), \n            \n            nn. Conv2d(in_channels=64, \n                       out_channels=128, \n                       kernel_size=3\n                       ), #64X12x12\n            nn.BatchNorm2d(128), \n            \n            nn.ReLU(), \n            \n            nn.Conv2d(in_channels=128, \n                       out_channels=128, \n                       kernel_size=3,\n                       padding=1),\n            nn. BatchNorm2d(128), \n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #128x6x6\n            nn.Dropout2d(p=0.3), \n            \n            nn.Conv2d(in_channels=128, \n                      out_channels=128, \n                      kernel_size=3, \n                      padding=1), #128x6x6\n            nn.BatchNorm2d(128), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=128, \n                      out_channels=256, \n                      kernel_size=3, \n                      padding=1), #256x6x6\n            nn.BatchNorm2d(256), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=256, \n                      out_channels=256, \n                      kernel_size=3, \n                      padding=1), \n            nn.BatchNorm2d(256), #256x6x6\n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #256x3x3\n            nn.Dropout2d(p=0.3), \n            \n            nn.Flatten(), #256x3x3\n            nn.Linear(256 *3*3, 372), \n            nn.ReLU() , \n            nn.Linear(372, emnist_num_classes) , \n        )\n   \n    def forward(self, x) :\n        return self.net(x) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torchsummary ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchsummary import summary \n\ntmodel = ThirdModel().to(device)\n\nsummary(tmodel, (1, 28, 28)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20\n\n\nmetric = Precision(task='multiclass', num_classes=emnist_num_classes).to(device)\nmetric_name = 'Precision'\n\n\n#model = FourthModel()\nmodel = ThirdModel() \n#model = model.to(device)\n\nif torch.cuda.is_available():\n    if torch.cuda.device_count() > 1:\n        print(f'Имеется {torch.cuda.device_count()} GPU') \n        model = nn.DataParallel(model) \n\nmodel.to(device) \n\ntitle = 'Third model'\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3) \n\nscheduler = StepLR(optimizer, step_size=7) \n\nloss_fn = nn.CrossEntropyLoss()\n\ntrain_test_cycle(model,\n                 num_epochs,\n                 loss_fn, \n                 train_loader,\n                 valid_loader,\n                 metric,\n                 metric_name,\n                 title, \n                 scheduler\n                )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение модели\nfrom datetime import  date\ntorch.save(model.state_dict(), f'{title}_{date.today()}.pth')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emnist_classes = {\n'0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9', \n'10': 'A', '11': 'B', '12': 'C', '13': 'D', '14': 'E', '15': 'F', '16': 'G', '17': 'H', '18': 'I', '19': 'J',\n'20': 'K', '21': 'L', '22': 'M', '23': 'N', '24': 'O', '25': 'P', '26': 'Q', '27': 'R', '28': 'S', '29': 'T', \n'30': 'U', '31': 'V', '32': 'W', '33': 'X', '34': 'Y', '35': 'Z', \n'36': 'a', '37': 'b', '38': 'c', '39': 'd', '40': 'e', '41': 'f', '42': 'g', '43': 'h', '44': 'i', '45': 'j',\n'46': 'k', '47': 'l', '48': 'm', '49': 'n', '50': 'o', '51': 'p', '52': 'q', '53': 'r', '54': 's', '55': 't',\n'56': 'u', '57': 'v', '58': 'w', '59': 'x', '60': 'y', '61': 'z'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# item_num = 4\n# device = torch.device('cpu')\n# model.to('cpu')\n\nfor item_num in np.random.randint(low = 3,high=10,size=10):\n    im = train_dataset[item_num]\n    plt.figure(figsize=(3, 3))\n    plt.title(f'Цифра {im[1]}')\n\n    plt.imshow(im[0][0])\n\n    print(model(im[0].to(device).unsqueeze(0)))\n    # получим предсказание модели\n    result_probab = model(im[0].to(device).unsqueeze(0))[0].detach().cpu().numpy()\n    # выведем индекс класса с максимальной вероятностью\n    im_class = result_probab.argmax()\n\n    print(f'Индекс наиболее вероятного класса: {im_class}')\n    # из словаря выведем Название цифры по типу\n    number = emnist_classes[str(im_class)]\n    print(f'На изображении цифра: {number}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}