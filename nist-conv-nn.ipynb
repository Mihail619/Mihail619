{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":10705,"sourceType":"datasetVersion","datasetId":7160},{"sourceId":2205796,"sourceType":"datasetVersion","datasetId":1093},{"sourceId":11506,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":9280}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mihaail/nist-conv-nn?scriptVersionId=164553747\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nfrom torch import optim\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader \nfrom torchmetrics import Accuracy, MeanAbsoluteError, Precision\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom tqdm import tqdm\nfrom torchvision.datasets import MNIST\nimport torchvision\nimport torchvision.transforms.v2 as T\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\n\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-27T06:09:15.490286Z","iopub.execute_input":"2024-02-27T06:09:15.4908Z","iopub.status.idle":"2024-02-27T06:09:24.843989Z","shell.execute_reply.started":"2024-02-27T06:09:15.490764Z","shell.execute_reply":"2024-02-27T06:09:24.843028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First model:\n  accuracy = 0.992\n  loss = \n\nSecond model: accuracy = 0.993\nloss = \n\nОбучение на датасете Emnist\nthird model: precision = 0.87\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Первая и вторая модель для обучения на датасете MNIST\nу этих моделей есть ошибка в том, что перед последним слоем стоит не softmax а ReLU\n","metadata":{}},{"cell_type":"markdown","source":"\n## 2. Третья модель \n1. Зафайнтюнить вторую модель для обучения на emnist не получилось. слишко плохое качество. precision=0.5. \n\n2. заменим метрику с accuracy на precision\n\n","metadata":{}},{"cell_type":"markdown","source":"\n## 3. Четвёрта модель\n2. заменяется ReLU перед последним слоем на softmax\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Оценим датасет EMNIST","metadata":{}},{"cell_type":"code","source":"# классы\nemnist_classes = {\n    '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, \n'10': ''}","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:24.849309Z","iopub.execute_input":"2024-02-27T06:09:24.849593Z","iopub.status.idle":"2024-02-27T06:09:24.85572Z","shell.execute_reply.started":"2024-02-27T06:09:24.849552Z","shell.execute_reply":"2024-02-27T06:09:24.854623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Создаем датасет и даталоадер. ","metadata":{}},{"cell_type":"code","source":"# Создадим и обработаем датасеты для БД MNIST\n# На 3-м этапе не запускаем этот код. \n# Дальше рабтаем с БД EMNIST\n'''\nmnist_train = MNIST(root= \"../datasets/mnist\", train=True, download=True, transform=T.ToTensor())                  \n\nmnist_train[2][0].shape\n\nplt.figure(figsize=(5, 4))\nplt.title(f'Цифра {mnist_train[15][1]}')\nplt.imshow(mnist_train[15][0][0])\n\nplt.show()\n\n# Зададим mean и std для нормализации входных данных\nmean = (mnist_train.data/255).mean().unsqueeze(0) \nstd = (mnist_train.data/255).std().unsqueeze(0) \nprint(f'{mean=}') \nprint(f'{std=}') \n\n# Зададим трансформацию для трейн и тест датасетов\ntrain_transforms = T.Compose(\n    [\n        T.ToTensor(),\n        T.Normalize(mean=mean, std=std), \n        T.RandomAdjustSharpness(sharpness_factor=2)\n    ]\n) \n\nvalid_transforms = T.Compose(\n    [\n        T.ToTensor(),\n        T.Normalize(mean=mean, std=std)\n        \n        \n    ]\n) \n\n\nmnist_train_dataset = MNIST(root= \"../datasets/mnist\", train=True, download=True, transform=train_transforms) \nmnist_valid_dataset = MNIST(root= \"../datasets/mnist\", train=False, download=True, transform=valid_transforms)\n'''\n\n# train_loader = DataLoader(mnist_train_dataset, batch_size=50, shuffle=True) \n# valid_loader = DataLoader(mnist_valid_dataset, batch_size=50, shuffle=True) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:24.858708Z","iopub.execute_input":"2024-02-27T06:09:24.859065Z","iopub.status.idle":"2024-02-27T06:09:24.873317Z","shell.execute_reply.started":"2024-02-27T06:09:24.859032Z","shell.execute_reply":"2024-02-27T06:09:24.872264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загружется и обрабатывается датасет EMNIST","metadata":{}},{"cell_type":"code","source":"# Создается класс для чтения dataset из csv файла \nclass CustomDatasetEMNIST():\n    def __init__(self, csv_file_path, \n                 transform=None,\n                 nrows=None,\n                 skiprows=None) :\n        '''nrows - кол-во строк которое необходимо подгрузить,\n        '''\n        super().__init__()\n        self.data, self.targets, self.dataframe = self._load_data(csv_file_path=csv_file_path, nrows=nrows, skiprows=skiprows)\n        \n        self.transform = transform\n        \n    def __len__(self) :\n        return len(self.data) \n    \n    def __getitem__(self, index) :\n       \n        img = self.data[index]\n        #print(f'1. {img.shape=} {img}/n') \n        img = img.unsqueeze(0)\n        #print(f'2.{img.shape=} {img}/n') \n        targets = int(self.targets[index])\n        # Повернем и отразим изображение для лучшего восприятия\n        img = torchvision.transforms.functional.rotate(img=img, angle=-90)\n        img = torch.flip(img, dims=(2,))\n        \n        #print(f'3 {img.shape} {img} /n') \n        \n        if self.transform is not None:\n            #print(f'3. {img.shape} {img}') \n\n            img = self.transform(img)\n            #print(f'4.{img.shape} {img}') \n\n            \n        return img, targets\n    \n    \n    def _load_data(self,\n                  csv_file_path,\n                  nrows,\n                  skiprows=None):\n        \n        df = pd.read_csv(csv_file_path, nrows=nrows, skiprows=skiprows) \n        \n        targets = torch.tensor(df.iloc[:,0].values)\n        \n        data = df.iloc[:,1:].values.reshape((len(df), 28, 28))\n        \n        return torch.tensor(data).float(), targets, df","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:24.87448Z","iopub.execute_input":"2024-02-27T06:09:24.874853Z","iopub.status.idle":"2024-02-27T06:09:24.890843Z","shell.execute_reply.started":"2024-02-27T06:09:24.874827Z","shell.execute_reply":"2024-02-27T06:09:24.889901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#чтобы не вычислять заново среднее и стандартное отклонение и не подгуржать датафрейм запишем эти данные как константы\n\n'''emnist_data = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-train.csv', transform=T.ToTensor())\n\n\n# Зададим mean и std для нормализации входных данных\nmean = (emnist_data.data/255).mean().unsqueeze(0) \nstd = (emnist_data.data/255).std().unsqueeze(0) \nprint(f'{mean=}') \nprint(f'{std=}') '''\n\nmean = torch.tensor([0.1736])\nstd = torch.tensor([0.3317])\n\n\n# Зададим трансформацию для трейн и тест датасетов\ntrain_transforms = T.Compose(\n    [\n        T.ToTensor(),\n        T.Normalize(mean=mean, std=std), \n        T.RandomAdjustSharpness(sharpness_factor=2)\n    ]\n) \n\nvalid_transforms = T.Compose(\n    [\n        T.ToTensor(),\n        T.Normalize(mean=mean, std=std)\n        \n        \n    ]\n) \n# plt.figure(figsize=(3, 3))\n# plt.title(f'Цифра {emnist_data[1][1]}')\n# plt.imshow(emnist_data[1][0][0])\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:24.892161Z","iopub.execute_input":"2024-02-27T06:09:24.892508Z","iopub.status.idle":"2024-02-27T06:09:24.924863Z","shell.execute_reply.started":"2024-02-27T06:09:24.89248Z","shell.execute_reply":"2024-02-27T06:09:24.923745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Для обучения не будем подгружать датасет. чтобы не занимать оперативную память \n'''\ndf = pd.read_csv('/kaggle/input/emnist/emnist-byclass-train.csv')\n\ndf.head(2)\n\n#выведем классы изображений и запишем их кол-во\nclasses = df.iloc[:,0]\nprint(np.sort(classes.unique()))\nemnist_num_classes = classes.nunique()\nprint(emnist_num_classes)\n\n#Оценим распределение классов в датасете\nplt.figure(figsize=(5,5))\nplt.hist(classes,bins=emnist_num_classes, orientation='horizontal', alpha=0.5)\nplt.show()\n\nКак видно из графика присутствует сильный перекос в классах данных\n'''\nemnist_num_classes = 62\n\ntrain_dataset = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-train.csv', \n                                    \n                                    #skiprows=200000,\n                                    nrows=400000, \n                                    transform=train_transforms) \nvalid_dataset = CustomDatasetEMNIST(csv_file_path='/kaggle/input/emnist/emnist-byclass-test.csv',  transform=valid_transforms) \n\ntrain_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True) \nvalid_loader = DataLoader(valid_dataset, batch_size=1000, shuffle=True) \n\n## Зададим функции обучения валидации и отрисовки графиков\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:12:09.018735Z","iopub.execute_input":"2024-02-27T06:12:09.019125Z","iopub.status.idle":"2024-02-27T06:12:54.480296Z","shell.execute_reply.started":"2024-02-27T06:12:09.019084Z","shell.execute_reply":"2024-02-27T06:12:54.479168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Зададим девайс для обучения        \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\nprint(device)\ntry:\n    print(torch.cuda.get_device_name())\nexcept:\n    print('GPU нету!')\n\ndef train(model: nn.Module,\n         loader: DataLoader,\n         loss_fn,\n         metric) -> tuple[float, float]: \n    \n    '''ф-я проводит обучение модели. \n    возвращает ошибку на трейновом датасете'''\n    \n    model.train()\n    total_loss = 0\n    total_metric = 0\n\n    for x, y in tqdm(loader, desc=\"Train\"):\n        x, y = x.to(device), y.to(device)\n        \n        optimizer.zero_grad() \n    \n        output = model(x) \n    \n        loss = loss_fn(output, y) \n        total_loss += loss.item()\n        \n        loss.backward() \n    \n        optimizer.step()\n        \n        total_metric +=  metric(output.detach(), y).item()\n        \n    total_loss /= len(loader)\n    total_metric /= len(loader) \n    \n    return total_loss, total_metric \n\n\n@torch.inference_mode() \ndef valid(model: nn.Module,\n         loader: DataLoader,\n         loss_fn,\n         metric) -> tuple[float, float] :\n    \n    '''Ф-я расчитывает ф-ю ошибки и метрику на валидационной выборке'''\n    model.eval() \n    \n    total_loss = 0\n    total_metric = 0\n    \n    for x, y in tqdm(loader, desc=\"Evaluation\"):\n        x, y = x.to(device), y.to(device)\n        \n        output = model(x) \n        \n        loss = loss_fn(output, y) \n        \n        total_loss += loss.item()\n        \n        total_metric += metric(output, y).item() \n        \n        \n    total_loss /= len(loader)\n    total_metric /= len(loader) \n    return total_loss, total_metric\n          \n\ndef plot_stats(\n    train_loss: tuple,\n    valid_loss: tuple, \n    train_metric: tuple, \n    valid_metric: tuple, \n    title: str,\n    metric_name: str ) :\n    '''Ф-я отрисовывает ошибку и метрику на тестовой и трейновой датасетах.\n    '''\n    plt.figure(figsize=(8, 5))\n    plt.title(f'{title} loss') \n    plt.plot(train_loss, label='Train loss') \n    plt.plot(valid_loss, label='Valid loss') \n    \n    plt.legend() \n    plt.grid() \n    \n    plt.figure(figsize=(8, 5))\n    plt.title(f'{title} {metric_name}')\n    plt.plot(train_metric, label=f'Train {metric_name}') \n    plt.plot(valid_metric, label=f'Valid {metric_name}') \n    plt.legend() \n    \n    plt.grid() \n    \n    plt.show() \n\n\n    \n#Функция обучения и валидации на всех эпохах\n\ndef train_test_cycle(model: nn.Module,\n                    num_epochs: int, \n                    loss_fn, \n                    train_loader: DataLoader, \n                    valid_loader: DataLoader,\n                    metric,\n                    metric_name: str,\n                    title: str,\n                    scheduler):\n    '''Ф-я проводит для каждой эпох обучение на трейновой выборке, валидацию для валидной выборки\n    и отрисовку графиков. '''\n    \n    train_loss_history, train_metric_history = [], []\n    valid_loss_history, valid_metric_history = [], []\n    \n    \n    for epoch in range(num_epochs): \n        train_loss, train_metric = train(model,\n                          train_loader, \n                          loss_fn,\n                          metric)\n        \n        valid_loss, valid_metric = valid(model, \n                           valid_loader, \n                           loss_fn, \n                           metric) \n        \n        train_loss_history.append(train_loss) \n        valid_loss_history.append(valid_loss) \n        \n        train_metric_history.append(train_metric) \n        valid_metric_history.append(valid_metric)\n                \n        clear_output()\n        \n        plot_stats(train_loss_history, \n                  valid_loss_history, \n                  train_metric_history, \n                  valid_metric_history, \n                  title,\n                  metric_name) \n        \n        scheduler.step() \n        print(f'Valid Loss: {valid_loss}') \n        print(f'Valid {metric_name}: {valid_metric}') \n\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:58.63459Z","iopub.execute_input":"2024-02-27T06:09:58.634887Z","iopub.status.idle":"2024-02-27T06:09:58.701756Z","shell.execute_reply.started":"2024-02-27T06:09:58.634861Z","shell.execute_reply":"2024-02-27T06:09:58.700712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Создаем объект нс","metadata":{}},{"cell_type":"code","source":"# Создадим класс (и архитектуру) первой модели\nclass FirstModel(nn.Module) :\n    def __init__(self) :\n        super().__init__() \n        # Размерность входного тензора: 1х28х28\n       \n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1), #16x28x28\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2), #16x14x14\n            nn. Conv2d(in_channels=16, \n                       out_channels=64, \n                       kernel_size=3\n                       ), #64X12x12\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size=2), #64x6x6\n            nn.Conv2d(in_channels=64, \n                      out_channels=128, \n                      kernel_size=3, \n                      padding=1), #128x6x6\n            \n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size=2), #128x3x3\n         \n            \n            nn.Flatten(), #128x3x3\n            nn.Linear(128*3*3, 200), \n            nn.ReLU() , \n            nn.Linear(200, 10) , \n        )\n   \n    def forward(self, x) :\n        return self.net(x) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:58.703122Z","iopub.execute_input":"2024-02-27T06:09:58.703447Z","iopub.status.idle":"2024-02-27T06:09:58.711859Z","shell.execute_reply.started":"2024-02-27T06:09:58.70342Z","shell.execute_reply":"2024-02-27T06:09:58.710846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим класс (и архитектуру) второй модели\nclass SecondModel(nn.Module) :\n    def __init__(self) :\n        super().__init__() \n        # Размерность входного тензора: 1х28х28\n       \n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1), #16x28x28\n            nn.BatchNorm2d(16), \n            nn.ReLU(),\n            \n            nn.MaxPool2d(kernel_size=2), #16x14x14\n            nn.Dropout2d(p=0.5), \n            \n            nn. Conv2d(in_channels=16, \n                       out_channels=64, \n                       kernel_size=3\n                       ), #64X12x12\n            nn.BatchNorm2d(64), \n            \n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #64x6x6\n            nn.Dropout2d(p=0.5), \n            \n            nn.Conv2d(in_channels=64, \n                      out_channels=128, \n                      kernel_size=3, \n                      padding=1), #128x6x6\n            nn.BatchNorm2d(128), \n            nn.ReLU(),\n            \n            nn.MaxPool2d(kernel_size=2), #128x3x3\n            nn.Dropout2d(p=0.5), \n            \n            nn.Flatten(), #128x3x3\n            nn.Linear(128*3*3, 200), \n            nn.ReLU() , \n            nn.Linear(200, 10) , \n        )\n   \n    def forward(self, x) :\n        return self.net(x) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:09:58.715502Z","iopub.execute_input":"2024-02-27T06:09:58.715878Z","iopub.status.idle":"2024-02-27T06:09:58.727814Z","shell.execute_reply.started":"2024-02-27T06:09:58.715846Z","shell.execute_reply":"2024-02-27T06:09:58.726825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим класс (и архитектуру) третьей модели. Для обучения на датасете EMNIST\n\nclass ThirdModel(nn.Module) :\n    def __init__(self) :\n        super().__init__() \n        # Размерность входного тензора: 1х28х28\n       \n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels=1,\n                      out_channels=64,\n                      kernel_size=3,\n                      padding=1), #32x28x28\n            nn.BatchNorm2d(64), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=64,\n                      out_channels=64,\n                      kernel_size=3, \n                      padding=1) , #32x28x28\n            nn.BatchNorm2d(64), \n            nn.ReLU(), \n     \n            \n            nn.MaxPool2d(kernel_size=2), #32x14x14\n            nn.Dropout2d(p=0.2), \n            \n            nn. Conv2d(in_channels=64, \n                       out_channels=128, \n                       kernel_size=3\n                       ), #64X12x12\n            nn.BatchNorm2d(128), \n            \n            nn.ReLU(), \n            \n            nn.Conv2d(in_channels=128, \n                       out_channels=128, \n                       kernel_size=3,\n                       padding=1),\n            nn. BatchNorm2d(128), \n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #64x6x6\n            nn.Dropout2d(p=0.3), \n            \n            nn.Conv2d(in_channels=128, \n                      out_channels=256, \n                      kernel_size=3, \n                      padding=1), #128x6x6\n            nn.BatchNorm2d(256), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=256, \n                      out_channels=256, \n                      kernel_size=3, \n                      padding=1), \n            nn.BatchNorm2d(256), #128x6x6\n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #128x3x3\n            nn.Dropout2d(p=0.3), \n            \n            nn.Flatten(), #64x3x3\n            nn.Linear(256*3*3, 300), \n            nn.ReLU() , \n            nn.Linear(300, emnist_num_classes) , \n        )\n   \n    def forward(self, x) :\n        return self.net(x) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:10:49.294169Z","iopub.execute_input":"2024-02-27T06:10:49.294598Z","iopub.status.idle":"2024-02-27T06:10:49.309253Z","shell.execute_reply.started":"2024-02-27T06:10:49.29455Z","shell.execute_reply":"2024-02-27T06:10:49.308223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим класс (и архитектуру) третьей модели. Для обучения на датасете EMNIST\n\nclass FourthModel(nn.Module) :\n    def __init__(self) :\n        super().__init__() \n        # Размерность входного тензора: 1х28х28\n       \n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels=1,\n                      out_channels=64,\n                      kernel_size=3,\n                      padding=1), #32x28x28\n            nn.BatchNorm2d(64), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=64,\n                      out_channels=64,\n                      kernel_size=3, \n                      padding=1) , #32x28x28\n            nn.BatchNorm2d(64), \n            nn.ReLU(), \n     \n            \n            nn.MaxPool2d(kernel_size=2), #32x14x14\n            nn.Dropout2d(p=0.2), \n            \n            nn. Conv2d(in_channels=64, \n                       out_channels=128, \n                       kernel_size=3\n                       ), #64X12x12\n            nn.BatchNorm2d(128), \n            \n            nn.ReLU(), \n            \n            nn.Conv2d(in_channels=128, \n                       out_channels=128, \n                       kernel_size=3,\n                       padding=1),\n            nn. BatchNorm2d(128), \n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #64x6x6\n            nn.Dropout2d(p=0.3), \n            \n            nn.Conv2d(in_channels=128, \n                      out_channels=256, \n                      kernel_size=3, \n                      padding=1), #128x6x6\n            nn.BatchNorm2d(256), \n            nn.ReLU(),\n            \n            nn.Conv2d(in_channels=256, \n                      out_channels=256, \n                      kernel_size=3, \n                      padding=1), \n            nn.BatchNorm2d(256), #128x6x6\n            nn.ReLU(), \n            \n            nn.MaxPool2d(kernel_size=2), #128x3x3\n            nn.Dropout2d(p=0.3), \n            \n            nn.Flatten(), #64x3x3\n            nn.Linear(256*3*3, 300), \n            nn.Softmax() , \n            nn.Linear(300, emnist_num_classes) , \n        )\n   \n    def forward(self, x) :\n        return self.net(x) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:10:49.294169Z","iopub.execute_input":"2024-02-27T06:10:49.294598Z","iopub.status.idle":"2024-02-27T06:10:49.309253Z","shell.execute_reply.started":"2024-02-27T06:10:49.29455Z","shell.execute_reply":"2024-02-27T06:10:49.308223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Зададим дополнительные параметры: ф-я потерь, оптимизатор","metadata":{}},{"cell_type":"code","source":"num_epochs = 13\n\n\nmetric = Precision(task='multiclass', num_classes=emnist_num_classes).to(device)\nmetric_name = 'Precision'\n\nmodel = ThirdModel().to(device)\n#model = model.to(device)\n\ntitle = 'Third model'\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3) \n\nscheduler = StepLR(optimizer, step_size=10) \n\nloss_fn = nn.CrossEntropyLoss()\n\ntrain_test_cycle(model,\n                 num_epochs,\n                 loss_fn, \n                 train_loader,\n                 valid_loader,\n                 metric,\n                 metric_name,\n                 title, \n                 scheduler\n                )\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T06:13:11.801935Z","iopub.execute_input":"2024-02-27T06:13:11.802335Z","iopub.status.idle":"2024-02-27T07:56:35.380217Z","shell.execute_reply.started":"2024-02-27T06:13:11.802302Z","shell.execute_reply":"2024-02-27T07:56:35.378292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение модели\ntorch.save(model.state_dict(), f'{title}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-02-27T07:56:46.319502Z","iopub.execute_input":"2024-02-27T07:56:46.320467Z","iopub.status.idle":"2024-02-27T07:56:46.345715Z","shell.execute_reply.started":"2024-02-27T07:56:46.320425Z","shell.execute_reply":"2024-02-27T07:56:46.344734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Загрузка модели\nload_model = SecondModel()\nload_model.load_state_dict(torch.load(f'{title}.pth'))\nload_model.eval()\n\n''' \n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:07:43.550467Z","iopub.status.idle":"2024-02-26T05:07:43.550923Z","shell.execute_reply.started":"2024-02-26T05:07:43.550695Z","shell.execute_reply":"2024-02-26T05:07:43.550714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ninput_object = 2\ninput_tensor = torch.tensor([input_object], dtype=torch.float32)\noutput_value = load_model(input_tensor).item()\noutput_value\n'''","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:07:43.551946Z","iopub.status.idle":"2024-02-26T05:07:43.552374Z","shell.execute_reply.started":"2024-02-26T05:07:43.552146Z","shell.execute_reply":"2024-02-26T05:07:43.552165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Зададим алгоритм предсказания на датасете MNIST \n'''\n# классы\nmnist_classes = {\n    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 9: '8', 9: '9'}\n\nmodel = SecondModel()\nmodel.load_state_dict(torch.load('/kaggle/input/emnist_model/pytorch/second_model/1/Second model.pth', map_location=torch.device('cpu')))\n\n#Оценим качество полученной модели\nmnist_dataset = MNIST(root= \"../datasets/mnist\", train=False, download=True, transform=T.ToTensor())\n\nitem_num = 4\nplt.figure(figsize=(3, 3))\nplt.title(f'Цифра {mnist_dataset[item_num][1]}')\nplt.imshow(mnist_dataset[item_num][0][0])\n\nplt.show()\n\n\n\nprint(model(mnist_dataset[item_num][0].unsqueeze(0)))\n\n# определим вектор вероятностей предсказания классов\nresult_probab = model(mnist_dataset[item_num][0].unsqueeze(0))[0].detach().numpy()\n\n# выведем индекс класса с максимальной вероятностью\nim_class = result_probab.argmax()\nprint(im_class)\n\n# из словаря выведем Название цифры по типу\nnumber = mnist_classes[im_class]\nprint(f'На изображении цифра: {number}')\n'''","metadata":{"execution":{"iopub.status.busy":"2024-02-26T17:34:01.038018Z","iopub.execute_input":"2024-02-26T17:34:01.038277Z","iopub.status.idle":"2024-02-26T17:34:01.050196Z","shell.execute_reply.started":"2024-02-26T17:34:01.038256Z","shell.execute_reply":"2024-02-26T17:34:01.049271Z"},"trusted":true},"execution_count":null,"outputs":[]}]}